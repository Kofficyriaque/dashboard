{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1364b85-0381-4e45-a459-302f0be8e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle # Pour sauvegarder le mod√®le\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "csv_path = \"C:/Users/Etu/Desktop/cleaned_dataset_domaine_info.csv\" \n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"üìä Donn√©es initiales : {len(df)} lignes\")\n",
    "\n",
    "\n",
    "# par precaution  On supprime les lignes sans salaire (Target)\n",
    "df = df.dropna(subset=['salaire_avg'])\n",
    "\n",
    "# On remplit les textes vides par \"\" pour √©viter les crashs\n",
    "text_cols = ['titre', 'description', 'competences', 'metier', 'experience', 'region']\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna(\"\")\n",
    "\n",
    "# B. SHUFFLE \n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(\"‚úÖ Donn√©es m√©lang√©es al√©atoirement.\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. FEATURE ENGINEERING\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "# On donne du poids au TITRE en le r√©p√©tant 2 fois\n",
    "df['text_features'] = (\n",
    "    df['titre'] + \" \" + df['titre'] + \" \" + \n",
    "    df['description'] + \" \" + \n",
    "    df['competences']\n",
    ")\n",
    "\n",
    "#  D√©finition des Variables (X) et de la Cible (y)\n",
    "features = ['text_features', 'metier', 'experience', 'region']\n",
    "X = df[features]\n",
    "y = df['salaire_avg']\n",
    "\n",
    "\n",
    "# 3. CONSTRUCTION DU PIPELINE du pipline du MOD√àLE\n",
    "\n",
    "\n",
    "# 1. Traitement du Texte (TF-IDF)\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english', # Supprime les mots inutiles\n",
    "    max_features=5000,    # On garde les 5000 mots les plus importants\n",
    "    ngram_range=(1, 2)    # Mots simples et paires \n",
    ")\n",
    "\n",
    "# 2. Traitement des Cat√©gories (OneHot)\n",
    "# Transforme \"Paris\", \"Lyon\" en colonnes binaires\n",
    "categorical = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# 3. Assemblage du Processeur\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('txt', tfidf, 'text_features'),\n",
    "        ('cat', categorical, ['metier', 'experience', 'region'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Pipeline Final (Processeur + Random Forest)\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "\n",
    "# 4. ENTRA√éNEMENT\n",
    "\n",
    "\n",
    "# S√©paration Train/Test (80% / 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\" Entra√Ænement sur {len(X_train)} offres... (Patientez)\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ==========================================\n",
    "# 5. VALIDATION & SCORES\n",
    "# ==========================================\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\" R√âSULTATS DU MOD√àLE\")\n",
    "print(\"-\" * 30)\n",
    "print(f\" Erreur Moyenne (MAE) : {mae:.0f} ‚Ç¨ / an\")\n",
    "print(f\"Pr√©cision (R¬≤)       : {r2:.3f}\")\n",
    "\n",
    "if r2 > 0.7:\n",
    "    print(\"Le mod√®le est PERFORMANT !\")\n",
    "else:\n",
    "    print(\" Le mod√®le peut √™tre am√©lior√©.\")\n",
    "\n",
    "\n",
    "# 6. TEST DE PR√âDICTION (Simulation)\n",
    "\n",
    "print(\"\\n Test R√©el :\")\n",
    "offre_test = pd.DataFrame({\n",
    "    'text_features': [\"D√©veloppeur Python Senior Django Flask API REST SQL\"],\n",
    "    'metier': [\"D√©veloppeur Logiciel\"],\n",
    "    'experience': [\"Senior (5+ ans)\"],\n",
    "    'region': [\"√éle-de-France\"]\n",
    "})\n",
    "\n",
    "pred = model.predict(offre_test)[0]\n",
    "print(f\"Offre : Dev Python Senior √† Paris\")\n",
    "print(f\"Salaire estim√© : {pred:.0f} ‚Ç¨\")\n",
    "\n",
    "\n",
    "# 7. SAUVEGARDE DU MOD√àLE \n",
    "\n",
    "with open(\"C:/Users/Etu/Desktop/salary_prediction_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "print(\"\\nMod√®le sauvegard√© dans 'salary_prediction_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc512913-117b-438f-92cb-1625f862c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. CHARGEMENT\n",
    "csv_path = \"C:/Users/Etu/Desktop/cleaned_dataset_domaine_info.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Nettoyage de base\n",
    "df = df.dropna(subset=['salaire_avg'])\n",
    "text_cols = ['titre', 'description', 'competences', 'metier', 'experience', 'region']\n",
    "for col in text_cols: df[col] = df[col].fillna(\"\")\n",
    "\n",
    "print(f\"üìä Donn√©es avant filtre : {len(df)}\")\n",
    "\n",
    "# 2. FILTRE DOUX (Seulement les erreurs manifestes)\n",
    "# On ne supprime QUE ce qui est impossible √† vivre (< 14k)\n",
    "# On GARDE les gros salaires (car ils sont r√©els dans la Tech)\n",
    "df = df[df['salaire_avg'] > 14000]\n",
    "\n",
    "print(f\" Donn√©es apr√®s filtre : {len(df)} (On a gard√© le maximum de mati√®re)\")\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 3. FEATURES\n",
    "df['text_features'] = (\n",
    "    df['titre'] + \" \" + df['titre'] + \" \" + \n",
    "    df['metier'] + \" \" + \n",
    "    df['competences'] + \" \" + \n",
    "    df['description']\n",
    ")\n",
    "\n",
    "X = df[['text_features', 'metier', 'experience', 'region']]\n",
    "y = df['salaire_avg']\n",
    "\n",
    "# 4. PIPELINE (RETOUR √Ä LA PUISSANCE BRUTE)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "categorical = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('txt', tfidf, 'text_features'),\n",
    "        ('cat', categorical, ['metier', 'experience', 'region'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# RANDOM FOREST PUISSANT\n",
    "# - n_estimators=200 : Suffisant et stable\n",
    "# - ON ENL√àVE 'max_features' : Il regarde tout (Lent mais Pr√©cis)\n",
    "# - ON ENL√àVE 'min_samples_leaf' : On le laisse apprendre les d√©tails\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(\n",
    "        n_estimators=200, \n",
    "        random_state=42, \n",
    "        n_jobs=-1 # Utilise tous les coeurs du PC pour aller vite quand m√™me\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 5. ENTRA√éNEMENT\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Entra√Ænement sur {len(X_train)} offres\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 6. R√âSULTATS\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\" MAE : {mae:.0f} ‚Ç¨\")\n",
    "print(f\" R¬≤  : {r2:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Sauvegarde\n",
    "with open(\"C:/Users/Etu/Desktop/salary_prediction_model_final.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a30bf-3554-41e5-a278-5ca3989041ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "csv_path = \"C:/Users/Etu/Desktop/cleaned_dataset_domaine_info.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Nettoyage\n",
    "df = df.dropna(subset=['salaire_avg'])\n",
    "\n",
    "df = df[df['salaire_avg'] > 14000]\n",
    "\n",
    "text_cols = ['titre', 'description', 'competences', 'metier', 'experience', 'region']\n",
    "for col in text_cols: df[col] = df[col].fillna(\"\")\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 2. FEATURES\n",
    "\n",
    "df['text_features'] = (\n",
    "    df['titre'] + \" \" + df['titre'] + \" \" + \n",
    "    df['metier'] + \" \" + \n",
    "    df['competences'] + \" \" + \n",
    "    df['description']\n",
    ")\n",
    "\n",
    "X = df[['text_features', 'metier', 'experience', 'region']]\n",
    "y = df['salaire_avg']\n",
    "\n",
    "\n",
    "# pipeline xgboost\n",
    "\n",
    "\n",
    "# TF-IDF (On garde une bonne taille pour nourrir le XGBoost)\n",
    "tfidf = TfidfVectorizer(\n",
    "    stop_words='english', \n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "categorical = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('txt', tfidf, 'text_features'),\n",
    "        ('cat', categorical, ['metier', 'experience', 'region'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(\n",
    "        n_estimators=1000, \n",
    "        learning_rate=0.05, \n",
    "        max_depth=6, \n",
    "        subsample=0.8,      \n",
    "        colsample_bytree=0.8, \n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "#  entrainement\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\" Entra√Ænement XGBoost sur {len(X_train)} offres...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\" RESULTATS XGBOOST\")\n",
    "print(\"-\" * 30)\n",
    "print(f\" MAE : {mae:.0f} ‚Ç¨\")\n",
    "print(f\" R¬≤  : {r2:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"C:/Users/Etu/Desktop/salary_model_xgboost2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"\\nMod√®le XGBoost sauvegard√©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefe163-9789-44bf-a517-18936d2739c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Configuration de la taille\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "\n",
    "plt.scatter(y_test, y_pred, color='#3b82f6', alpha=0.5, s=60, edgecolors='white', label='Pr√©dictions')\n",
    "\n",
    "# 3. La Ligne Rouge \"Id√©ale\" (Si tout √©tait parfait)\n",
    "# On trace une ligne du min au max\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p1, p2], [p1, p2], 'r--', linewidth=2, label='Perfect (Id√©al)')\n",
    "\n",
    "\n",
    "texte_scores = (\n",
    "    f\"MODELE XGBOOST\\n\"\n",
    "    f\"-----------------------\\n\"\n",
    "    f\"R¬≤ (regression metric) = {r2:.3f}\\n\"  # ex: 0.706\n",
    "    f\"MAE (Erreur)   = {mae:.0f} ‚Ç¨\" # ex: 3954 ‚Ç¨\n",
    ")\n",
    "\n",
    "# On place la bo√Æte (bbox)\n",
    "plt.text(0.05, 0.95, texte_scores, transform=plt.gca().transAxes,\n",
    "         fontsize=12, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='gray'))\n",
    "\n",
    "# 5. Titres et Labels\n",
    "plt.title(f'Performance : Salaires R√©els vs Salaires Pr√©dits', fontsize=15, fontweight='bold')\n",
    "plt.xlabel('Vrai Salaire Annuel (‚Ç¨)', fontsize=12)\n",
    "plt.ylabel('Salaire Estim√© par le mod√®le (‚Ç¨)', fontsize=12)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# 6. Affichage\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bdd70b-1782-42df-87f3-f5bfa5989a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "X_train_full, X_test_fixe, y_train_full, y_test_fixe = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1.0, 6) # 6 √©tapes\n",
    "r2_scores = []\n",
    "mae_scores = []\n",
    "n_rows = []\n",
    "\n",
    "\n",
    "\n",
    "# 2. LA BOUCLE D'ENTRA√éNEMENT PROGRESSIF\n",
    "for fraction in train_sizes:\n",
    "    # On prend une fraction des donn√©es d'entra√Ænement (ex: les 1000 premi√®res lignes, puis 2000...)\n",
    "    # On convertit la fraction en nombre entier\n",
    "    size = int(len(X_train_full) * fraction) \n",
    "    \n",
    "    # D√©coupage des donn√©es partielles\n",
    "    X_partial = X_train_full[:size]\n",
    "    y_partial = y_train_full[:size]\n",
    "    \n",
    "    # On entra√Æne le mod√®le (XGBoost) sur cette petite partie\n",
    "    # Note : On utilise le m√™me pipeline 'model' que tu as d√©fini avant\n",
    "    model.fit(X_partial, y_partial)\n",
    "    \n",
    "    # On teste sur le jeu de test FIXE (toujours le m√™me pour bien comparer)\n",
    "    y_pred_partial = model.predict(X_test_fixe)\n",
    "    \n",
    "    # On enregistre les scores\n",
    "    r2 = r2_score(y_test_fixe, y_pred_partial)\n",
    "    mae = mean_absolute_error(y_test_fixe, y_pred_partial)\n",
    "    \n",
    "    r2_scores.append(r2)\n",
    "    mae_scores.append(mae)\n",
    "    n_rows.append(size)\n",
    "    \n",
    "    print(f\" Entrainer sur {size} lignes -> R¬≤={r2:.3f} | MAE={mae:.0f}‚Ç¨\")\n",
    "\n",
    "# 3. VISUALISATION (Double Graphique)\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Axe Y gauche : Le R¬≤ (Doit monter)\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Nombre de lignes utilis√©es pour l\\'entra√Ænement', fontsize=12)\n",
    "ax1.set_ylabel('regresion metric ($R^2$)', color=color, fontsize=12)\n",
    "ax1.plot(n_rows, r2_scores, marker='o', color=color, linewidth=3, label='$R^2$ (Pr√©cision)')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Axe Y droit : Le MAE (Doit descendre)\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Mean error (MAE en ‚Ç¨)', color=color, fontsize=12)\n",
    "ax2.plot(n_rows, mae_scores, marker='s', color=color, linewidth=3, linestyle='--', label='MAE Erreur')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Titre et Mise en forme\n",
    "plt.title(\"Courbe D'apprentisage\", fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6f1c1-3dc5-471c-821b-7da00d4e38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "csv_path = \"C:/Users/Etu/Desktop/cleaned_dataset_domaine_info.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Nettoyage\n",
    "df = df.dropna(subset=['salaire_avg'])\n",
    "df = df[df['salaire_avg'] > 14000]\n",
    "\n",
    "text_cols = ['titre', 'description', 'competences', 'metier', 'experience', 'region']\n",
    "for col in text_cols: df[col] = df[col].fillna(\"\")\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 2. PR√âPARATION DES DONN√âES (X et y)\n",
    "\n",
    "df['text_features'] = (\n",
    "    df['titre'] + \" \" + df['titre'] + \" \" + \n",
    "    df['metier'] + \" \" + \n",
    "    df['competences'] + \" \" + \n",
    "    df['description']\n",
    ")\n",
    "\n",
    "X = df[['text_features', 'metier', 'experience', 'region']]\n",
    "y = df['salaire_avg'].values # .values pour avoir un tableau numpy\n",
    "\n",
    "\n",
    "# 3. VECTORISATION \n",
    "\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1, 2))\n",
    "# OneHot\n",
    "categorical = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('txt', tfidf, 'text_features'),\n",
    "        ('cat', categorical, ['metier', 'experience', 'region'])\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "print(\" Transformation des donn√©es pour le r√©seau de neurones...\")\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Conversion en dense (si le TF-IDF sort du sparse) pour que TensorFlow soit content\n",
    "if hasattr(X_transformed, \"toarray\"):\n",
    "    X_transformed = X_transformed.toarray()\n",
    "\n",
    "# Split Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(f\"üìä Entr√©es du r√©seau : {input_dim} neurones (Mots + Cat√©gories)\")\n",
    "\n",
    "\n",
    "# ARCHITECTURE \"L√âG√àRE\" \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# On passe de 256 √† 64 neurones en entr√©e\n",
    "\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.4)) \n",
    "\n",
    "# Une seule couche cach√©e de 32 neurones \n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Sortie\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# On garde le m√™me optimiseur\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_absolute_error')\n",
    "\n",
    "\n",
    "# 5. ENTRA√éNEMENT (Training)\n",
    "\n",
    "# Early Stopping : Arr√™te si le mod√®le ne s'am√©liore plus apr√®s 10 √©poques\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "print(\"D√©marrage du Deep Learning...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=100,       # Max essais\n",
    "    batch_size=32,    # Paquets de donn√©es\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# 6. √âVALUATION FINALE\n",
    "\n",
    "y_pred = model.predict(X_test).flatten() # flatten pour avoir un tableau 1D\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\" R√âSULTATS DEEP LEARNING (TENSORFLOW)\")\n",
    "print(\"=\"*30)\n",
    "print(f\" MAE : {mae:.0f} ‚Ç¨\")\n",
    "print(f\" R¬≤  : {r2:.4f}\")\n",
    "\n",
    "\n",
    "# On sauvegarde le mod√®le au format .keras \n",
    "model.save(\"C:/Users/Etu/Desktop/salary_model_deeplearning.keras\")\n",
    "print(\"\\nüíæ Mod√®le Deep Learning sauvegard√© dans 'salary_model_deeplearning.keras'\")\n",
    "\n",
    "# On doit AUSSI sauvegarder le pr√©processeur (TF-IDF + OneHot)\n",
    "# Sinon, on ne pourra pas transformer les nouveaux textes pour l'utiliser !\n",
    "import pickle\n",
    "with open(\"C:/Users/Etu/Desktop/preprocessor_dl.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "print(\"Pr√©processeur sauvegard√© dans 'preprocessor_dl.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056474b4-7a89-4636-85a4-0cf63f147df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# On r√©cup√®re l'historique\n",
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, 'bo', label='Perte Entra√Ænement')\n",
    "plt.plot(epochs, val_loss, 'r', label='Perte Validation') \n",
    "plt.title('Preuve de la convergence (Training vs Validation)')\n",
    "plt.xlabel('√âpoques')\n",
    "plt.ylabel('Erreur (MAE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597c7bb-2e65-42aa-b949-fc6bb69e3491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e4fc7-fd1e-4e45-b84f-e525aebb1985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
