import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import google.generativeai as genai
import os
import json
import numpy as np
from datetime import datetime, timedelta
import time 
import pickle 
from collections import Counter  
from rag_engine import process_pdf_and_create_vector_db, get_rag_chain 
from pypdf import PdfReader
from sklearn.metrics.pairwise import cosine_similarity
from langchain_community.embeddings import HuggingFaceEmbeddings
import numpy as np
from langchain_huggingface import HuggingFaceEndpoint
from langchain_core.output_parsers import JsonOutputParser  
from langchain_groq import ChatGroq  
from dotenv import load_dotenv
# ==========================================
# 1. CONFIGURATION & STYLING PRO
# ==========================================
st.set_page_config(page_title="PredicIT", page_icon="üíº", layout="wide", initial_sidebar_state="expanded") 
# Charger les variables du fichier .env
load_dotenv()  

# R√©cup√©rer la cl√©
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
MODEL_NAME = "llama-3.3-70b-versatile" # Un des meilleurs mod√®les au monde, gratuit sur Groq

st.markdown("""
<style>
    /* R√©duire le vide en haut de page */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
        padding-left: 2rem;
        padding-right: 2rem;
    }
    
    /* Style des titres H1, H2, H3 */
    h1, h2, h3 {
        color: #0f172a; 
        font-family: 'Inter', sans-serif;
        font-weight: 700;
    }
    
    /* Style des Cartes KPI (Metric Cards) */
    div[data-testid="metric-container"] {
        background-color: white;
        border: 1px solid #e2e8f0;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }

    /* Supprimer l'espace vide sous les graphiques Plotly */
    .js-plotly-plot .plotly .modebar {
        display: none !important; /* Cache la barre d'outils au survol */
    }
    
    /* Style des onglets (Tabs) */
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #f1f5f9;
        border-radius: 5px 5px 0 0;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #ffffff;
        border-top: 2px solid #2563eb;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. HELPER FUNCTIONS & MOCK ML MODEL
# ==========================================

# --- Placeholder for your specific ML Model Loading ---

@st.cache_resource
def load_prediction_model():
    """Loads the real XGBoost model."""
    model_path = "salary_model_xgboost.pkl"
    
    if os.path.exists(model_path):
        with open(model_path, "rb") as f:
            model = pickle.load(f)
        return model
    else:
        st.error("Model file not found. Please put 'salary_model_xgboost.pkl' in the folder.")
        return None






@st.cache_data(show_spinner=False)
def extract_job_keywords(job_text):
    if not job_text or len(job_text) < 10:
        return []

    # 1. Initialize the Parser
    parser = JsonOutputParser()

    # 2. Initialize the LLM (Groq)
    llm = ChatGroq(
        temperature=0.1,
        groq_api_key=GROQ_API_KEY,
        model_name="llama-3.3-70b-versatile"
    )

    # 3. Enhanced Prompt for strict JSON
    prompt_text = f"""
    You are a Technical Recruiter. Extract technical keywords from this job description.
    Return ONLY a JSON list of objects with keys: "keyword", "type", "importance_score".
    
    JOB TEXT:
    {job_text}
    
    Format instructions: {parser.get_format_instructions()}
    """

    try:
        # We use a chain: Prompt -> LLM -> Parser
        # The parser automatically handles stripping ```json ``` blocks
        chain = llm | parser
        response = chain.invoke(prompt_text)
        
        # Ensure it returns a list
        return response if isinstance(response, list) else []
        
    except Exception as e:
        # If there is a parsing error, we print it for debug but return empty list to keep app running
        print(f"DEBUG - Parsing Error: {e}")
        return []
# ==========================================
# 3. DATA LOADING
# ==========================================
@st.cache_data
def load_data():
    # POINT TO YOUR REAL FILE
    path = "data/cleaned_dataset_domaine_info.csv" 
    
    if os.path.exists(path):
        df = pd.read_csv(path)
        # Ensure salary is numeric
        df['salaire_avg'] = pd.to_numeric(df['salaire_avg'], errors='coerce')
        df = df.dropna(subset=['salaire_avg'])
        
        # Create a fake date if you don't have one (for the charts)
        # If you scrapped it, ensure it is converted to datetime
        if 'date_publication' not in df.columns:
            # Fake dates for the dashboard visuals
            df['date_publication'] = pd.date_range(end=datetime.now(), periods=len(df)).tolist()
        else:
            df['date_publication'] = pd.to_datetime(df['date_publication'])
            
        return df
    else:
        st.error(f"File not found: {path}")
        return pd.DataFrame() # Return empty if fail 


def get_top_skills_for_job(df, job_name):
    """R√©cup√®re les 5 comp√©tences les plus cit√©es pour un m√©tier donn√©"""
    # 1. On filtre les offres du m√©tier
    subset = df[df['metier'] == job_name]
    
    # 2. On rassemble tous les textes de comp√©tences
    all_text = ",".join(subset['competences'].dropna().astype(str).tolist())
    
    # 3. On nettoie et on compte
    skills_list = [s.strip().title() for s in all_text.split(',') if len(s.strip()) > 1]
    counter = Counter(skills_list)
    
    # 4. On retourne les 5 plus fr√©quents
    return [s[0] for s in counter.most_common(5)]
@st.cache_data
def load_geojson(scale="regions"):
    """
    Charge le GeoJSON des R√©gions ou des D√©partements.
    """
    urls = {
        "regions": "https://france-geojson.gregoiredavid.fr/repo/regions.geojson",
        "departements": "https://france-geojson.gregoiredavid.fr/repo/departements.geojson"
    }
    
    try:
        import requests
        r = requests.get(urls[scale])
        return r.json()
    except Exception as e:
        st.error(f"Erreur de chargement de la carte ({scale}): {e}")
        return None
df = load_data()
geojson = load_geojson() 

@st.cache_resource
def load_embedding_model():
    # On charge le mod√®le une seule fois pour gagner du temps
    return HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

def rank_cvs(uploaded_files, job_description):
    """
    Compare une liste de CVs avec une description de poste.
    Retourne un DataFrame avec les scores.
    """
    embed_model = load_embedding_model()
    
    # 1. Vectoriser l'offre d'emploi (La r√©f√©rence)
    job_vector = embed_model.embed_query(job_description)
    job_vector = np.array([job_vector]) # Format n√©cessaire pour le calcul
    
    results = []
    
    # 2. Boucle sur chaque CV
    progress_bar = st.progress(0)
    for i, file in enumerate(uploaded_files):
        # Lecture PDF
        try:
            reader = PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text()
            
            # Vectoriser le CV
            cv_vector = embed_model.embed_query(text)
            cv_vector = np.array([cv_vector])
            
            # Calcul du Score (0 √† 100%)
            score = cosine_similarity(job_vector, cv_vector)[0][0]
            
            results.append({
                "Nom du Fichier": file.name,
                "Score de Pertinence": round(score * 100, 2), # En pourcentage
                "Texte Brut": text[:500] + "..." # Juste pour preview
            })
        except Exception as e:
            print(f"Erreur fichier {file.name}: {e}")
            
        # Mise √† jour barre de progression
        progress_bar.progress((i + 1) / len(uploaded_files))
        
    progress_bar.empty() # Enlever la barre √† la fin
    
    # Cr√©ation du DataFrame tri√©
    df_results = pd.DataFrame(results)
    if not df_results.empty:
        df_results = df_results.sort_values(by="Score de Pertinence", ascending=False)
        
    return df_results

# ==========================================
# 4. SIDEBAR & INPUTS
# ==========================================

st.sidebar.image("https://cdn-icons-png.flaticon.com/512/3098/3098090.png", width=50) 
st.sidebar.title("Configuration")

# 1. Metier (Category) - Gets list from your CSV
target_metier = st.sidebar.selectbox("M√©tier", options=sorted(df['metier'].unique()))

# 2. Region - Gets list from your CSV
target_region = st.sidebar.selectbox("R√©gion", options=sorted(df['region'].unique()))

# 3. Experience (CRITICAL for your model)
# These MUST match exactly what is in your CSV column 'experience_finale'
# Adjust these strings if your CSV is slightly different (e.g. "Junior (0-2 ans)")
exp_options = ["Junior (0-2 ans)", "Interm√©diaire (2-5 ans)", "Senior (5+ ans)", "Non sp√©cifi√©"]
target_experience = st.sidebar.selectbox("Exp√©rience", options=exp_options)

# 4. Job Title
target_title = st.sidebar.text_input("Intitul√© du Poste", "Data Scientist")

# 5. Description
target_desc = st.sidebar.text_area("Description de l'offre", height=200, placeholder="Collez la description ici...")

# Optional manual skills (Kept for filtering, though model uses Description)
known_skills = ["Python", "SQL", "Java", "AWS", "Azure", "Docker", "Kubernetes", "React", "Terraform"]
target_skills = st.sidebar.multiselect("Comp√©tences Cl√©s (Filtre Dashboard)", known_skills)

predict_btn = st.sidebar.button("‚ú® Lancer la Pr√©diction", use_container_width=True)

# Session State for prediction persistence
if 'prediction' not in st.session_state:
    st.session_state['prediction'] = None
if 'extracted_skills' not in st.session_state:
    st.session_state['extracted_skills'] = []

# ==========================================
# 5. MAIN LOGIC FLOW
# ==========================================

# HEADER
st.title("PredicIT ‚Ä¢ Talent Intelligence & Compensation Analytics")
st.markdown(f"Analyse de march√© pour **{target_metier}** en **{target_region}**.")
st.divider()

# ==========================================
# 6. LOGIQUE DE PR√âDICTION & LOADING
# ==========================================

if predict_btn:
    if not target_desc:
        st.error("‚ö†Ô∏è Veuillez coller une description d'offre.")
    else:
        # --- LOADING "MATRIX" ---
        with st.status(" Initialisation ", expanded=True) as status:
            st.write("Connexion ...")
            time.sleep(0.8)
            
            st.write(" Analyse s√©mantique description...")
            ai_skills = extract_job_keywords(target_desc)
            st.session_state['extracted_skills'] = ai_skills
            time.sleep(0.5)
            
            st.write("Agr√©gation des donn√©es r√©gionales...")
            # Pr√©paration des inputs pour le mod√®le
            skills_str = ", ".join([s['keyword'] for s in ai_skills]) if ai_skills else ""
            
            model = load_prediction_model()
            
            if model:
                text_input = (
                    str(target_title) + " " + str(target_title) + " " + 
                    str(target_metier) + " " + 
                    str(skills_str) + " " + 
                    str(target_desc)
                )
                
                input_df = pd.DataFrame({
                    'text_features': [text_input],
                    'metier': [target_metier],
                    'experience': [target_experience],
                    'region': [target_region]
                })
                
                try:
                    pred_val = model.predict(input_df)[0]
                    pred_min = pred_val * 0.9
                    pred_max = pred_val * 1.1
                    st.session_state['prediction'] = {"val": pred_val, "range": (pred_min, pred_max)}
                    
                    status.update(label="‚úÖ Analyse termin√©e avec succ√®s !", state="complete", expanded=False)
                    
                except Exception as e:
                    status.update(label="‚ùå Erreur critique", state="error")
                    st.error(f"Erreur : {e}")
            else:
                st.error("Mod√®le introuvable.")

# ==========================================
# 7. AFFICHAGE DU DASHBOARD (BLOC UNIQUE)
# ==========================================

if st.session_state['prediction']:
    pred = st.session_state['prediction']
    
    st.write("") 

    # --- A. HEADER & BOUTON DOWNLOAD (HAUT GAUCHE) ---
    col_dl, col_title = st.columns([1, 4])
    
    with col_dl:
        # G√©n√©ration HTML pour PDF
        html_report = f"""
        <html>
        <head><title>Rapport {target_metier}</title></head>
        <body style="font-family: Arial; padding: 40px;">
            <h1 style="color: #2563eb;">Rapport : {target_metier}</h1>
            <p><strong>R√©gion :</strong> {target_region}</p>
            <hr>
            <h2>üí∞ Estimation : {pred['val']:,.0f} ‚Ç¨ / an</h2>
            <br><p><em>G√©n√©r√© par PrediSalaire.ai</em></p>
        </body>
        </html>
        """
        st.download_button(
            label="üì• T√©l√©charger Rapport",
            data=html_report,
            file_name=f"Rapport_{target_metier}.html",
            mime="text/html",
            use_container_width=True,
            key="btn_download_header" # Cl√© unique pour √©viter l'erreur
        )

    with col_title:
        st.markdown(f"### üìç Analyse : **{target_metier}** en **{target_region}**")

    st.markdown("---")

    # --- B. LA CARTE INTERACTIVE (EN PREMIER) ---
    col_map_filters, col_map_viz = st.columns([1, 3])
    
    with col_map_filters:
        st.markdown("#### ‚öôÔ∏è Carte")
        # AJOUT DES CL√âS UNIQUES (key=...) POUR CORRIGER TON ERREUR
        view_mode = st.radio("üìç Zoom :", ["R√©gion", "D√©partement"], index=0, key="radio_map_zoom")
        st.write("") 
        metric_label = st.radio("üìä Indicateur :", ["M√©diane", "Moyenne"], index=0, key="radio_map_metric")
        metric_func = 'median' if "M√©diane" in metric_label else 'mean'

    with col_map_viz:
        if view_mode == "R√©gion":
            map_df = df[df['metier'] == target_metier].groupby('region')['salaire_avg'].agg(metric_func).reset_index()
            geojson = load_geojson("regions")
            loc_col, key_json, zoom_lvl = 'region', "properties.nom", 4.5
        else: 
            map_df = df[df['metier'] == target_metier].groupby('departement')['salaire_avg'].agg(metric_func).reset_index()
            map_df['departement'] = map_df['departement'].astype(str).str.zfill(2)
            geojson = load_geojson("departements")
            loc_col, key_json, zoom_lvl = 'departement', "properties.code", 5.0

        if geojson:
            fig_map = px.choropleth_mapbox(
                map_df, geojson=geojson, locations=loc_col, featureidkey=key_json,
                color='salaire_avg', color_continuous_scale="Blues",
                mapbox_style="carto-positron", zoom=zoom_lvl, center={"lat": 46.6, "lon": 2.2},
                opacity=0.7, labels={'salaire_avg': f'{metric_label} (‚Ç¨)'}
            )
            fig_map.update_layout(margin={"r":0,"t":0,"l":0,"b":0}, height=450)
            st.plotly_chart(fig_map, use_container_width=True)
        else:
            st.error("Carte indisponible.")

    # --- C. INDICATEURS CL√âS (KPIs) ---
    st.markdown("### üìä Indicateurs Cl√©s")
    
    col1, col2, col3, col4 = st.columns(4)
    
    mask_context = (df['metier'] == target_metier) & (df['region'] == target_region)
    market_data = df[mask_context]
    market_val = market_data['salaire_avg'].median() if not market_data.empty else 0
    sample_size = len(market_data)
    
    with col1:
        st.markdown(f"""<div class="metric-card"><div class="metric-label">Salaire Estim√© (IA)</div><div class="metric-value highlight">{pred['val']:,.0f} ‚Ç¨</div></div>""", unsafe_allow_html=True)
    with col2:
        st.markdown(f"""<div class="metric-card"><div class="metric-label">March√© ({target_region})</div><div class="metric-value">{market_val:,.0f} ‚Ç¨</div></div>""", unsafe_allow_html=True)
    with col3:
        st.markdown(f"""<div class="metric-card"><div class="metric-label">Fourchette Probable</div><div class="metric-value" style="font-size:1.4rem">{pred['range'][0]:,.0f} - {pred['range'][1]:,.0f}</div></div>""", unsafe_allow_html=True)
    with col4:
        conf_txt = "√âlev√©e" if sample_size > 30 else "Faible"
        st.markdown(f"""<div class="metric-card"><div class="metric-label">Fiabilit√©</div><div class="metric-value">{conf_txt}</div><small>{sample_size} offres</small></div>""", unsafe_allow_html=True)

    st.markdown("---")

    # --- D. ANALYSE D√âTAILL√âE ---
    col_bench, col_ai = st.columns([1, 1], gap="medium")

    with col_bench:
        with st.container(border=True):
            st.markdown("#### Comparateur de M√©tiers")
            all_metiers = sorted(df['metier'].unique())
            try: default_ix = all_metiers.index("Data Engineer")
            except: default_ix = 0
            comp_metier = st.selectbox("Comparer avec :", all_metiers, index=default_ix, key="sb_compare_metier")
            
            df_curr = df[df['metier'] == target_metier]
            df_comp = df[df['metier'] == comp_metier]
            med_curr = df_curr['salaire_avg'].median()
            med_comp = df_comp['salaire_avg'].median()
            
            fig_comp = go.Figure(data=[
                go.Bar(name=target_metier, x=[target_metier], y=[med_curr], marker_color='#2563eb', text=f"{med_curr:,.0f}‚Ç¨", textposition='auto'),
                go.Bar(name=comp_metier, x=[comp_metier], y=[med_comp], marker_color='#94a3b8', text=f"{med_comp:,.0f}‚Ç¨", textposition='auto')
            ])
            fig_comp.update_layout(title="Salaire M√©dian Compar√©", height=300, margin=dict(l=20, r=20, t=30, b=20), showlegend=False)
            st.plotly_chart(fig_comp, use_container_width=True, config={'displayModeBar': False})
            
            st.markdown("**Top Comp√©tences :**")
            skills_curr = get_top_skills_for_job(df, target_metier)
            skills_comp = get_top_skills_for_job(df, comp_metier)
            c1, c2 = st.columns(2)
            with c1:
                for s in skills_curr[:4]: st.caption(f"üîπ {s}")
            with c2:
                for s in skills_comp[:4]: st.caption(f"üî∏ {s}")

    with col_ai:
        with st.container(border=True):
            st.markdown("#### Analyse des competences de votre Offre ")
            if st.session_state['extracted_skills']:
                skills_df = pd.DataFrame(st.session_state['extracted_skills']).sort_values('importance_score', ascending=True)
                fig_skills = px.bar(
                    skills_df, x="importance_score", y="keyword", orientation='h',
                    color="importance_score", color_continuous_scale="Teal",
                    title="Mots-cl√©s d√©tect√©s"
                )
                fig_skills.update_layout(title=None, height=400, margin=dict(l=0, r=0, t=0, b=0), showlegend=False, xaxis=dict(showticklabels=False, title=None), yaxis=dict(title=None))
                st.plotly_chart(fig_skills, use_container_width=True, config={'displayModeBar': False})
            else:
                st.info("Collez une description pour voir l'analyse.")

    st.markdown("---")

    # ==========================================
    # 8. CENTRE DE CARRI√àRE & RECRUTEMENT
    # ==========================================
    st.header("Centre de Recrutement & Carri√®re")
tab_candidat, tab_recruteur = st.tabs(["üë§ Espace Candidat (Coach IA)", "üè¢ Espace Recruteur (Tri CVs)"])

with tab_candidat:
    st.info(f"**Mode Coaching:** Posez vos questions sur votre compatibilit√© avec le poste.")
    col_cv, col_chat = st.columns([1, 2])

    with col_cv:
        uploaded_cv = st.file_uploader("Analysez votre CV (PDF)", type=["pdf"], key="cv_upload_candidat")
        if uploaded_cv: st.success("‚úÖ CV charg√©")

    with col_chat:
        # Initialisation m√©moire
        if "messages_candidat" not in st.session_state:
            st.session_state.messages_candidat = []
        if "vector_store_candidat" not in st.session_state:
            st.session_state.vector_store_candidat = None

        # Traitement RAG avec le nouveau moteur
        if uploaded_cv and st.session_state.vector_store_candidat is None:
            with st.spinner(" Analyse du CV..."):
                st.session_state.vector_store_candidat = process_pdf_and_create_vector_db(uploaded_cv)
                st.rerun()

        # Affichage Chat
        chat_container = st.container(height=350)
        with chat_container:
            for msg in st.session_state.messages_candidat:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

        if uploaded_cv:
            b1, b2, b3 = st.columns(3)
            action_prompt = None
            if b1.button("üìä Analyser CV", use_container_width=True):
                action_prompt = "Analyse mon CV par rapport √† ce poste. Points forts/faibles ?"
            if b2.button("‚öñÔ∏è Comparer", use_container_width=True):
                action_prompt = f"Donne mon score de compatibilit√© pour le poste de {target_metier}."
            if b3.button("üìù Lettre Motiv'", use_container_width=True):
                action_prompt = "R√©dige une lettre de motivation courte."

            if action_prompt:
                st.session_state.messages_candidat.append({"role": "user", "content": action_prompt})
                with chat_container:
                    with st.chat_message("user"): st.markdown(action_prompt)
                    with st.chat_message("assistant"):
                        with st.spinner("r√©fl√©chit..."):
                            # APPEL AU NOUVEAU RAG ENGINE
                            qa_chain = get_rag_chain(st.session_state.vector_store_candidat, GROQ_API_KEY)
                            
                            full_query = f"ACTION: {action_prompt} | OFFRE: {target_desc[:500]}"
                            response = qa_chain.invoke(full_query)
                            
                            st.session_state.messages_candidat.append({"role": "assistant", "content": response})
                            st.markdown(response)
                    
                  
                    # On laisse Streamlit finir le script. Au prochain clic, l'historique sera r√©affich√© par le bloc 3.
    # --- ONGLET 2 : RECRUTEUR (Bulk) ---
    with tab_recruteur:
        st.markdown("#### üìÇ Analyse d'un dossier de resume")
        st.write(f"Identifiez instantan√©ment les meilleurs profils pour le poste de **{target_metier}**.")
        uploaded_files = st.file_uploader("Glissez-d√©posez les CVs (PDF)", type=['pdf'], accept_multiple_files=True, key="bulk_upload")
        
        if uploaded_files:
            if st.button(f" Analyser {len(uploaded_files)} CVs", key="btn_launch_bulk"):
                with st.spinner("Classement en cours..."):
                    ranked_df = rank_cvs(uploaded_files, target_desc)
                    st.success("Termin√© !")
                    if len(ranked_df) >= 3:
                        c1, c2, c3 = st.columns(3)
                        c1.metric("ü•á Top 1", ranked_df.iloc[0]['Nom du Fichier'], f"{ranked_df.iloc[0]['Score de Pertinence']}%")
                        c2.metric("ü•à Top 2", ranked_df.iloc[1]['Nom du Fichier'], f"{ranked_df.iloc[1]['Score de Pertinence']}%")
                        c3.metric("ü•â Top 3", ranked_df.iloc[2]['Nom du Fichier'], f"{ranked_df.iloc[2]['Score de Pertinence']}%")
                    
                    st.dataframe(
                        ranked_df[['Score de Pertinence', 'Nom du Fichier']], 
                        use_container_width=True, 
                        column_config={"Score de Pertinence": st.column_config.ProgressColumn("Pertinence", format="%.1f%%", min_value=0, max_value=100)}
                    )